{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tokenization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maneesh51/NLP_Udemy_Course/blob/main/Tokenization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# https://spacy.io/usage/spacy-101"
      ],
      "metadata": {
        "id": "ck6dd30oy0QV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "S = ['Hi there Mr. Longbottom.', \"How're you today?\", 'Apple is a fruit, buy it online www.google.com', 'I am in U.S.A.']\n",
        "S"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qVjhqpTbTpy",
        "outputId": "7ad25184-b502-4590-b387-b923081eea57"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hi there Mr. Longbottom.',\n",
              " \"How're you today?\",\n",
              " 'Apple is a fruit, buy it online www.google.com',\n",
              " 'I am in U.S.A.']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "ifV27FBlbrDh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### some pre-trained models in spacy\n",
        "\n",
        "M1 = spacy.load(name='en_core_web_sm')\n",
        "\n",
        "### medium sized model need to be downloaded \n",
        "!python -m spacy download en_core_web_md\n",
        "\n",
        "import en_core_web_md\n",
        "M2 = en_core_web_md.load()"
      ],
      "metadata": {
        "id": "EaM2AaXNbZYC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "023fd6be-55a3-45de-e6d2-ef36fca46a5f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en_core_web_md==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.5/en_core_web_md-2.2.5.tar.gz (96.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 96.4 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_md==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.9.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.21.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (4.64.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (4.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.4)\n",
            "Building wheels for collected packages: en-core-web-md\n",
            "  Building wheel for en-core-web-md (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-md: filename=en_core_web_md-2.2.5-py3-none-any.whl size=98051301 sha256=61426c3cebd5cb485b66ac008c941755056ed05431b436be90faf85c63cbcb44\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-inb0mutl/wheels/69/c5/b8/4f1c029d89238734311b3269762ab2ee325a42da2ce8edb997\n",
            "Successfully built en-core-web-md\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "M1S=[]; M2S=[]\n",
        "for i in range(len(S)):\n",
        "  M1S.append(M1(S[i]))\n",
        "  M2S.append(M2(S[i]))\n"
      ],
      "metadata": {
        "id": "DIseA6fwcjzY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in M1S[2]:\n",
        "  print(token)\n",
        "for token in M2S[2]:\n",
        "  print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EVVWGuAfeL8",
        "outputId": "6bf96090-9ebc-444a-c65a-12d6391e7ea0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple\n",
            "is\n",
            "a\n",
            "fruit\n",
            ",\n",
            "buy\n",
            "it\n",
            "online\n",
            "www.google.com\n",
            "Apple\n",
            "is\n",
            "a\n",
            "fruit\n",
            ",\n",
            "buy\n",
            "it\n",
            "online\n",
            "www.google.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(M1S[2]),'\\n', len(M1S[2]))"
      ],
      "metadata": {
        "id": "rWvBWGqhfeOc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71378e76-eb94-4bbd-cf60-6801c17a0035"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'spacy.tokens.doc.Doc'> \n",
            " 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Nk8_IX7Ekb0d"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stemming and lemmatization"
      ],
      "metadata": {
        "id": "wz4NZSEEmbyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['run', 'runner', 'running', 'ran', 'runs', 'easily', 'mature']"
      ],
      "metadata": {
        "id": "tjm1gMXlkb2w"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem.snowball import SnowballStemmer"
      ],
      "metadata": {
        "id": "UFKJbrqomfd5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Stemming NLTK functions \n",
        "\n",
        "p_stemmer = PorterStemmer()\n",
        "s_stemmer = SnowballStemmer(language='english')\n",
        "\n",
        "for word in words:\n",
        "  print(word, '----', p_stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRPLtq3vnBPv",
        "outputId": "d1eafb3d-0437-49c9-d90c-1c8ae8b976bd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run ---- run\n",
            "runner ---- runner\n",
            "running ---- run\n",
            "ran ---- ran\n",
            "runs ---- run\n",
            "easily ---- easili\n",
            "mature ---- matur\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "  print(word, '----', s_stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8K3KpOznBSA",
        "outputId": "808f2cf2-ee12-40f2-aefe-c03d81fad840"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run ---- run\n",
            "runner ---- runner\n",
            "running ---- run\n",
            "ran ---- ran\n",
            "runs ---- run\n",
            "easily ---- easili\n",
            "mature ---- matur\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VEsJWCjymfgN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Lemmatiztion \n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "irm_wEA3mfiQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"There are several important topics needs to be discussed now, but let's do it tomorrow.\"\n",
        "doc1 = nlp(sentence)"
      ],
      "metadata": {
        "id": "wryylmPRpRKS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc1:\n",
        "  print(token.text, '\\t', token.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPHoB8RlpIL_",
        "outputId": "3173a5e1-c118-4d07-fab0-678fd4cfc178"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There \t there\n",
            "are \t be\n",
            "several \t several\n",
            "important \t important\n",
            "topics \t topic\n",
            "needs \t need\n",
            "to \t to\n",
            "be \t be\n",
            "discussed \t discuss\n",
            "now \t now\n",
            ", \t ,\n",
            "but \t but\n",
            "let \t let\n",
            "'s \t -PRON-\n",
            "do \t do\n",
            "it \t -PRON-\n",
            "tomorrow \t tomorrow\n",
            ". \t .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in sentence.split():\n",
        "  print(word, '----', p_stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZVXe-zBpINx",
        "outputId": "909c995c-5362-4d0b-ad2b-cc06b12ec8e5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There ---- there\n",
            "are ---- are\n",
            "several ---- sever\n",
            "important ---- import\n",
            "topics ---- topic\n",
            "needs ---- need\n",
            "to ---- to\n",
            "be ---- be\n",
            "discussed ---- discuss\n",
            "now, ---- now,\n",
            "but ---- but\n",
            "let's ---- let'\n",
            "do ---- do\n",
            "it ---- it\n",
            "tomorrow. ---- tomorrow.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "p7_9ydosrAtX"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stop words"
      ],
      "metadata": {
        "id": "VMCHxE-9rUu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(nlp.Defaults.stop_words), '\\n', nlp.Defaults.stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuu5fmEtrWJO",
        "outputId": "15c1e638-c93f-4d39-83ba-376cddb44f6b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "326 \n",
            " {'last', 'even', 'being', 'our', 'somehow', 'cannot', 'more', 'her', 'did', 'as', 'such', 'least', 'each', 'may', \"'ll\", 'thereafter', 'third', 'for', 'while', 'various', 'well', 'and', 'itself', '‘m', 'both', \"'s\", 'could', 'might', 'namely', 'bottom', 'hers', 'next', 'between', 'several', 'yet', 'of', 'into', 'you', 'still', 'thereby', 'amongst', 'again', 'must', 'first', 'together', 'every', 'to', 'ca', 'so', 'just', 'ten', 'whole', 'this', 'yourself', 'too', 'they', 'thereupon', 'whereby', '‘s', 'had', 'sometimes', 'whereupon', 'why', 'eleven', '‘re', 'beforehand', 'move', 'will', 'hereby', 'below', 'whither', '‘ve', 'take', 'them', 'anyone', 'there', 'only', 'six', 'very', 'were', 'rather', 'would', 'meanwhile', 'whose', 'show', 'their', 'whether', 'not', 'elsewhere', 'without', 'has', 'twelve', 'put', 'say', 'is', 'at', 'become', 'should', 'after', 'although', 'if', 'was', 'herself', 'he', 'how', 'regarding', 'get', 'much', 'by', 'we', 'the', 'been', 'many', 'used', 'are', 'onto', 'top', 'via', 'yourselves', 'go', 'hereafter', 'be', 'myself', 'became', 'off', 'three', 'seemed', 'during', 'these', 'seeming', 'due', 'us', 'either', 'some', 'ever', 'around', '’d', 'keep', '’ve', 'moreover', 're', 'she', 'never', 'nor', 'up', 'it', 'another', 'whom', 'which', 'him', 'own', 'name', 'nowhere', 'beside', 'wherever', 'along', 'anywhere', 'really', 'above', 'its', 'no', 'under', 'call', 'empty', 'because', 'whoever', 'yours', 'wherein', 'against', 'else', 'others', 'ours', 'about', 'what', 'see', 'sixty', 'across', 'whereafter', 'sometime', \"'ve\", 'already', 'among', 'throughout', 'ourselves', 'himself', 'everywhere', 'perhaps', \"'re\", 'those', 'but', 'mine', 'anything', 'often', 'whenever', '’ll', 'until', 'on', 'towards', 'everyone', 'does', 'few', 'then', 'thru', 'someone', 'done', 'eight', 'beyond', 'since', 'unless', '’m', 'quite', 'something', 'than', 'who', 'his', 'indeed', '’re', 'give', 'forty', 'none', 'nothing', 'therefore', 'anyhow', \"'d\", 'one', 'further', 'whence', 'other', '‘d', 'nine', 'where', \"n't\", 'an', 'formerly', 'therein', 'same', 'per', 'your', 'except', 'behind', 'from', 'can', 'amount', 'full', 'hence', 'over', 'four', 'five', 'n‘t', 'afterwards', 'becoming', 'all', 'back', 'always', '’s', 'alone', 'everything', 'within', 'two', 'besides', 'herein', 'almost', 'before', 'fifty', 'make', 'latter', 'made', 'themselves', 'here', 'toward', 'though', 'or', 'that', 'n’t', 'former', 'doing', 'nevertheless', 'do', \"'m\", 'when', 'upon', 'hundred', 'noone', 'whereas', 'any', 'a', 'side', 'serious', 'have', 'whatever', 'through', 'otherwise', 'seem', 'nobody', 'latterly', 'most', '‘ll', 'enough', 'twenty', 'with', 'please', 'in', 'thence', 'i', 'somewhere', 'however', 'front', 'mostly', 'me', 'anyway', 'now', 'once', 'less', 'fifteen', 'becomes', 'also', 'using', 'am', 'down', 'part', 'neither', 'hereupon', 'seems', 'thus', 'my', 'out'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.vocab['always'].is_stop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hR5KvulxrWLq",
        "outputId": "3204896d-79cc-4956-9bda-f0e7d6f81b55"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## adding more keywords to our stop word list"
      ],
      "metadata": {
        "id": "kRNqmTuns0DY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "New_word = 'haha'\n",
        "nlp.Defaults.stop_words.add(New_word) \n",
        "print(len(nlp.Defaults.stop_words), '\\n', nlp.Defaults.stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-1WRCPIrWN5",
        "outputId": "5546d09d-3179-4ebd-eec4-8bce2fa3f45f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "327 \n",
            " {'last', 'even', 'being', 'our', 'somehow', 'cannot', 'more', 'her', 'did', 'as', 'such', 'least', 'each', 'may', \"'ll\", 'thereafter', 'third', 'for', 'while', 'various', 'well', 'and', 'itself', '‘m', 'both', \"'s\", 'could', 'might', 'namely', 'bottom', 'hers', 'next', 'between', 'several', 'yet', 'of', 'into', 'you', 'still', 'thereby', 'amongst', 'again', 'must', 'first', 'together', 'every', 'to', 'ca', 'so', 'just', 'ten', 'whole', 'this', 'yourself', 'too', 'they', 'thereupon', 'whereby', '‘s', 'had', 'sometimes', 'whereupon', 'why', 'eleven', '‘re', 'beforehand', 'move', 'will', 'hereby', 'below', 'whither', '‘ve', 'take', 'them', 'anyone', 'there', 'only', 'six', 'very', 'haha', 'were', 'rather', 'would', 'meanwhile', 'whose', 'show', 'their', 'whether', 'not', 'elsewhere', 'without', 'has', 'twelve', 'put', 'say', 'is', 'at', 'become', 'should', 'after', 'although', 'if', 'was', 'herself', 'he', 'how', 'regarding', 'get', 'much', 'by', 'we', 'the', 'been', 'many', 'used', 'are', 'onto', 'top', 'via', 'yourselves', 'go', 'hereafter', 'be', 'myself', 'became', 'off', 'three', 'seemed', 'during', 'these', 'seeming', 'due', 'us', 'either', 'some', 'ever', 'around', '’d', 'keep', '’ve', 'moreover', 're', 'she', 'never', 'nor', 'up', 'it', 'another', 'whom', 'which', 'him', 'own', 'name', 'nowhere', 'beside', 'wherever', 'along', 'anywhere', 'really', 'above', 'its', 'no', 'under', 'call', 'empty', 'because', 'whoever', 'yours', 'wherein', 'against', 'else', 'others', 'ours', 'about', 'what', 'see', 'sixty', 'across', 'whereafter', 'sometime', \"'ve\", 'already', 'among', 'throughout', 'ourselves', 'himself', 'everywhere', 'perhaps', \"'re\", 'those', 'but', 'mine', 'anything', 'often', 'whenever', '’ll', 'until', 'on', 'towards', 'everyone', 'does', 'few', 'then', 'thru', 'someone', 'done', 'eight', 'beyond', 'since', 'unless', '’m', 'quite', 'something', 'than', 'who', 'his', 'indeed', '’re', 'give', 'forty', 'none', 'nothing', 'therefore', 'anyhow', \"'d\", 'one', 'further', 'whence', 'other', '‘d', 'nine', 'where', \"n't\", 'an', 'formerly', 'therein', 'same', 'per', 'your', 'except', 'behind', 'from', 'can', 'amount', 'full', 'hence', 'over', 'four', 'five', 'n‘t', 'afterwards', 'becoming', 'all', 'back', 'always', '’s', 'alone', 'everything', 'within', 'two', 'besides', 'herein', 'almost', 'before', 'fifty', 'make', 'latter', 'made', 'themselves', 'here', 'toward', 'though', 'or', 'that', 'n’t', 'former', 'doing', 'nevertheless', 'do', \"'m\", 'when', 'upon', 'hundred', 'noone', 'whereas', 'any', 'a', 'side', 'serious', 'have', 'whatever', 'through', 'otherwise', 'seem', 'nobody', 'latterly', 'most', '‘ll', 'enough', 'twenty', 'with', 'please', 'in', 'thence', 'i', 'somewhere', 'however', 'front', 'mostly', 'me', 'anyway', 'now', 'once', 'less', 'fifteen', 'becomes', 'also', 'using', 'am', 'down', 'part', 'neither', 'hereupon', 'seems', 'thus', 'my', 'out'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.vocab[New_word].is_stop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgWdKmQVrWP4",
        "outputId": "77be29b4-9d8e-4343-df23-ef421ca2afb1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## removing more keywords to our stop word list"
      ],
      "metadata": {
        "id": "I2NZ5OfltEFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.Defaults.stop_words.remove(New_word) \n",
        "nlp.vocab[New_word].is_stop = False\n",
        "print(nlp.vocab[New_word].is_stop, '\\n', len(nlp.Defaults.stop_words), '\\n', nlp.Defaults.stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acrnL6sGrWRm",
        "outputId": "f2546d70-ae47-402d-b19f-80837f528205"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False \n",
            " 326 \n",
            " {'last', 'even', 'being', 'our', 'somehow', 'cannot', 'more', 'her', 'did', 'as', 'such', 'least', 'each', 'may', \"'ll\", 'thereafter', 'third', 'for', 'while', 'various', 'well', 'and', 'itself', '‘m', 'both', \"'s\", 'could', 'might', 'namely', 'bottom', 'hers', 'next', 'between', 'several', 'yet', 'of', 'into', 'you', 'still', 'thereby', 'amongst', 'again', 'must', 'first', 'together', 'every', 'to', 'ca', 'so', 'just', 'ten', 'whole', 'this', 'yourself', 'too', 'they', 'thereupon', 'whereby', '‘s', 'had', 'sometimes', 'whereupon', 'why', 'eleven', '‘re', 'beforehand', 'move', 'will', 'hereby', 'below', 'whither', '‘ve', 'take', 'them', 'anyone', 'there', 'only', 'six', 'very', 'were', 'rather', 'would', 'meanwhile', 'whose', 'show', 'their', 'whether', 'not', 'elsewhere', 'without', 'has', 'twelve', 'put', 'say', 'is', 'at', 'become', 'should', 'after', 'although', 'if', 'was', 'herself', 'he', 'how', 'regarding', 'get', 'much', 'by', 'we', 'the', 'been', 'many', 'used', 'are', 'onto', 'top', 'via', 'yourselves', 'go', 'hereafter', 'be', 'myself', 'became', 'off', 'three', 'seemed', 'during', 'these', 'seeming', 'due', 'us', 'either', 'some', 'ever', 'around', '’d', 'keep', '’ve', 'moreover', 're', 'she', 'never', 'nor', 'up', 'it', 'another', 'whom', 'which', 'him', 'own', 'name', 'nowhere', 'beside', 'wherever', 'along', 'anywhere', 'really', 'above', 'its', 'no', 'under', 'call', 'empty', 'because', 'whoever', 'yours', 'wherein', 'against', 'else', 'others', 'ours', 'about', 'what', 'see', 'sixty', 'across', 'whereafter', 'sometime', \"'ve\", 'already', 'among', 'throughout', 'ourselves', 'himself', 'everywhere', 'perhaps', \"'re\", 'those', 'but', 'mine', 'anything', 'often', 'whenever', '’ll', 'until', 'on', 'towards', 'everyone', 'does', 'few', 'then', 'thru', 'someone', 'done', 'eight', 'beyond', 'since', 'unless', '’m', 'quite', 'something', 'than', 'who', 'his', 'indeed', '’re', 'give', 'forty', 'none', 'nothing', 'therefore', 'anyhow', \"'d\", 'one', 'further', 'whence', 'other', '‘d', 'nine', 'where', \"n't\", 'an', 'formerly', 'therein', 'same', 'per', 'your', 'except', 'behind', 'from', 'can', 'amount', 'full', 'hence', 'over', 'four', 'five', 'n‘t', 'afterwards', 'becoming', 'all', 'back', 'always', '’s', 'alone', 'everything', 'within', 'two', 'besides', 'herein', 'almost', 'before', 'fifty', 'make', 'latter', 'made', 'themselves', 'here', 'toward', 'though', 'or', 'that', 'n’t', 'former', 'doing', 'nevertheless', 'do', \"'m\", 'when', 'upon', 'hundred', 'noone', 'whereas', 'any', 'a', 'side', 'serious', 'have', 'whatever', 'through', 'otherwise', 'seem', 'nobody', 'latterly', 'most', '‘ll', 'enough', 'twenty', 'with', 'please', 'in', 'thence', 'i', 'somewhere', 'however', 'front', 'mostly', 'me', 'anyway', 'now', 'once', 'less', 'fifteen', 'becomes', 'also', 'using', 'am', 'down', 'part', 'neither', 'hereupon', 'seems', 'thus', 'my', 'out'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xEQO1t-JsvgZ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vL5sYPwisvi2"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vacabulary and matching\n",
        "\n",
        "### 1. Rule-based matching - https://explosion.ai/demos/matcher\n",
        "and\n",
        "### 2. Phrase matching"
      ],
      "metadata": {
        "id": "WjKogLsntzkP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### 1. Rule-based matching\n",
        "\n",
        "from spacy.matcher import Matcher\n",
        "matcher = Matcher(nlp.vocab)"
      ],
      "metadata": {
        "id": "TXSFwWJqt-Nk"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### creating a list of dictionary of hello world\n",
        "\n",
        "pattern1 = [{'LOWER': 'hello'}, {'LOWER': 'world'}]\n",
        "pattern2 = [{'LOWER': 'hello'}, {'IS_PUNCT': True}, {'LOWER': 'world'}]\n",
        "\n",
        "### add patterns to matcher object\n",
        "matcher.add('Hello World', None, pattern1, pattern2)"
      ],
      "metadata": {
        "id": "DplNdUN3r1Up"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Here goes an example of 'Hello World', let's see if Hello ?-&! World or hello WoRld or hello! world perfectly works\"\n",
        "doc = nlp(text)\n",
        "\n",
        "doc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fi9umS6ztVFt",
        "outputId": "e0ba6d15-e908-41b0-c3d8-86942a7214b6"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Here goes an example of 'Hello World', let's see if Hello ?-&! World or hello WoRld or hello! world perfectly works"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Finding the matches"
      ],
      "metadata": {
        "id": "6XI-RhMuuIcX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### passing doc to another matcher object\n",
        "### it returns string id, inder start and index end\n",
        "find_matches = matcher(doc) \n",
        "find_matches"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4M_wa3UStVH-",
        "outputId": "156a20ed-c2c3-46cf-a244-3a21a44a83b2"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(8585552006568828647, 6, 8),\n",
              " (8585552006568828647, 21, 23),\n",
              " (8585552006568828647, 24, 27)]"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### defining a function to find the matches\n",
        "\n",
        "for match_id, start, end in find_matches:\n",
        "  ### get sting representation\n",
        "  string_id = nlp.vocab.strings[match_id]\n",
        "  ### get matched span\n",
        "  span = doc[start:end]\n",
        "  print(match_id, string_id, start, end, span.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTdarAwtt-Pl",
        "outputId": "1cf23f81-a4c8-4cb6-c347-e334d6e8d7c5"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8585552006568828647 Hello World 6 8 Hello World\n",
            "8585552006568828647 Hello World 21 23 hello WoRld\n",
            "8585552006568828647 Hello World 24 27 hello! world\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### adding multiple numbers of puncttuation between hello and world"
      ],
      "metadata": {
        "id": "2xxtDbgvxJ8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### creating a list of dictionary of hello world\n",
        "\n",
        "pattern3 = [{'LOWER': 'hello'}, {'LOWER': 'world'}]\n",
        "pattern4 = [{'LOWER': 'hello'}, {'IS_PUNCT': True, 'OP':'*'}, {'LOWER': 'world'}]\n",
        "\n",
        "### add patterns to matcher object\n",
        "matcher.add('Hello World', None, pattern3, pattern4)"
      ],
      "metadata": {
        "id": "9ZpPs4fut-RZ"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "find_matches = matcher(doc) \n",
        "\n",
        "for match_id, start, end in find_matches:\n",
        "  ### get sting representation\n",
        "  string_id = nlp.vocab.strings[match_id]\n",
        "  ### get matched span\n",
        "  span = doc[start:end]\n",
        "  print(match_id, string_id, start, end, span.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pVZ0dAvsvlA",
        "outputId": "8059e40c-e08a-4270-bdf2-d7dcf4337dbb"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8585552006568828647 Hello World 6 8 Hello World\n",
            "8585552006568828647 Hello World 14 20 Hello ?-&! World\n",
            "8585552006568828647 Hello World 21 23 hello WoRld\n",
            "8585552006568828647 Hello World 24 27 hello! world\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "26SfyBbtsvnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Phrase-based matching"
      ],
      "metadata": {
        "id": "mcTR_QRCzVQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "phrase_list = ['Barack Obama', 'Angela Merkel', 'Washington D.C.']"
      ],
      "metadata": {
        "id": "YLl-3TS5pIPp"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.matcher import PhraseMatcher\n",
        "matcher = PhraseMatcher(nlp.vocab)"
      ],
      "metadata": {
        "id": "hKG0i5UwzYYo"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### first making spacy tokens as before\n",
        "\n",
        "phrase_patterns = [nlp(text) for text in phrase_list]\n",
        "\n",
        "print(type(phrase_patterns[0]), '\\n', phrase_patterns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZiwwtfpzvyI",
        "outputId": "f77834b9-c312-4f87-8f7a-b0a2444957b4"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'spacy.tokens.doc.Doc'> \n",
            " [Barack Obama, Angela Merkel, Washington D.C.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### IMPORTANT !!! phrase objects are not strings \n",
        "### adding to phrases to matcher, marker by * sign\n",
        "\n",
        "matcher.add('TerminologyList', None, *phrase_patterns)\n"
      ],
      "metadata": {
        "id": "XJmVehUgzv0a"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc3 = nlp(\"German chancellor Angela Merkel or Angela-Merkel met US president Barack Obama. The meeting was held in Washington D.C. with Angela-Merkel.\")"
      ],
      "metadata": {
        "id": "_xnxkF-G1TFp"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "find_matches = matcher(doc3)\n",
        "\n",
        "print(find_matches)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5byIwr_71xo1",
        "outputId": "aa601566-8eaf-461b-ad98-9c64ddafb2d4"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(3766102292120407359, 2, 4), (3766102292120407359, 11, 13), (3766102292120407359, 19, 21)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "find_matches = matcher(doc3) \n",
        "\n",
        "for match_id, start, end in find_matches:\n",
        "  ### get sting representation\n",
        "  string_id = nlp.vocab.strings[match_id]\n",
        "  ### get matched span\n",
        "  span = doc3[start:end]\n",
        "  print(match_id, string_id, start, end, span.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USbqtzEv1xsL",
        "outputId": "67ab4648-b6ad-43e1-f206-7f842e81014f"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3766102292120407359 TerminologyList 2 4 Angela Merkel\n",
            "3766102292120407359 TerminologyList 11 13 Barack Obama\n",
            "3766102292120407359 TerminologyList 19 21 Washington D.C.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WgHPe5hFzv2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parts of speech tagging\n",
        "### Eg. nouns, verbs, adjectives etc.."
      ],
      "metadata": {
        "id": "67aao2ws39aV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s1 = \"she is a smart woman but extermely talkitive 10% : $150505, how about an ice-cream and bike?\"\n",
        "doc = nlp(s1)"
      ],
      "metadata": {
        "id": "k3cIAbxczYa_"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "  print(token.text, token.pos_, token.tag, spacy.explain(token.tag_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJZV4-GQzYde",
        "outputId": "e6db3169-3a61-496f-d345-96fd1f750db4"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "she PRON 13656873538139661788 pronoun, personal\n",
            "is AUX 13927759927860985106 verb, 3rd person singular present\n",
            "a DET 15267657372422890137 determiner\n",
            "smart ADJ 10554686591937588953 adjective\n",
            "woman NOUN 15308085513773655218 noun, singular or mass\n",
            "but CCONJ 17571114184892886314 conjunction, coordinating\n",
            "extermely ADV 164681854541413346 adverb\n",
            "talkitive ADJ 10554686591937588953 adjective\n",
            "10 NUM 8427216679587749980 cardinal number\n",
            "% NOUN 15308085513773655218 noun, singular or mass\n",
            ": PUNCT 11532473245541075862 punctuation mark, colon or ellipsis\n",
            "$ SYM 11283501755624150392 symbol, currency\n",
            "150505 NUM 8427216679587749980 cardinal number\n",
            ", PUNCT 2593208677638477497 punctuation mark, comma\n",
            "how ADV 17524233984504158541 wh-adverb\n",
            "about ADP 1292078113972184607 conjunction, subordinating or preposition\n",
            "an DET 15267657372422890137 determiner\n",
            "ice NOUN 15308085513773655218 noun, singular or mass\n",
            "- PUNCT 8214596291009089021 punctuation mark, hyphen\n",
            "cream NOUN 15308085513773655218 noun, singular or mass\n",
            "and CCONJ 17571114184892886314 conjunction, coordinating\n",
            "bike NOUN 15308085513773655218 noun, singular or mass\n",
            "? PUNCT 12646065887601541794 punctuation mark, sentence closer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### grammatical analysis\n",
        "\n",
        "for key, val in doc.count_by(spacy.attrs.POS).items():\n",
        "  print(key, doc.vocab[key].text, val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbigkdOEzYew",
        "outputId": "c24785c3-76b9-4b10-d1b6-a0da0f23dc67"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "95 PRON 1\n",
            "87 AUX 1\n",
            "90 DET 2\n",
            "84 ADJ 2\n",
            "92 NOUN 5\n",
            "89 CCONJ 2\n",
            "86 ADV 2\n",
            "93 NUM 2\n",
            "97 PUNCT 4\n",
            "99 SYM 1\n",
            "85 ADP 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "\n",
        "displacy.render(docs=doc, style='dep', options={'distance':80}, jupyter=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "4dnLzDQizYhP",
        "outputId": "c1d1c320-730f-4fce-9879-882461abb4ca"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"2d8b926f65894b0ebb633a0ac3085069-0\" class=\"displacy\" width=\"1490\" height=\"377.0\" direction=\"ltr\" style=\"max-width: none; height: 377.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">she</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"130\">is</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"130\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"210\">a</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"210\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"290\">smart</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"290\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"370\">woman</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"370\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"450\">but</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"450\">CCONJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"530\">extermely</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"530\">ADV</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"610\">talkitive</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"610\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"690\">10% :</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"690\">NUM</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">$</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">SYM</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"850\">150505,</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"850\">NUM</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"930\">how</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"930\">ADV</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1010\">about</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1010\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1090\">an</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1090\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1170\">ice-</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1170\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1250\">cream</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1250\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1330\">and</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1330\">CCONJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1410\">bike?</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1410\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-2d8b926f65894b0ebb633a0ac3085069-0-0\" stroke-width=\"2px\" d=\"M70,242.0 C70,202.0 105.0,202.0 105.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-2d8b926f65894b0ebb633a0ac3085069-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,244.0 L62,232.0 78,232.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-2d8b926f65894b0ebb633a0ac3085069-0-1\" stroke-width=\"2px\" d=\"M230,242.0 C230,162.0 350.0,162.0 350.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-2d8b926f65894b0ebb633a0ac3085069-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M230,244.0 L222,232.0 238,232.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-2d8b926f65894b0ebb633a0ac3085069-0-2\" stroke-width=\"2px\" d=\"M310,242.0 C310,202.0 345.0,202.0 345.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-2d8b926f65894b0ebb633a0ac3085069-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M310,244.0 L302,232.0 318,232.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-2d8b926f65894b0ebb633a0ac3085069-0-3\" stroke-width=\"2px\" d=\"M150,242.0 C150,122.0 355.0,122.0 355.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-2d8b926f65894b0ebb633a0ac3085069-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M355.0,244.0 L363.0,232.0 347.0,232.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-2d8b926f65894b0ebb633a0ac3085069-0-4\" stroke-width=\"2px\" d=\"M150,242.0 C150,82.0 440.0,82.0 440.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-2d8b926f65894b0ebb633a0ac3085069-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M440.0,244.0 L448.0,232.0 432.0,232.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-2d8b926f65894b0ebb633a0ac3085069-0-5\" stroke-width=\"2px\" d=\"M550,242.0 C550,202.0 585.0,202.0 585.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-2d8b926f65894b0ebb633a0ac3085069-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M550,244.0 L542,232.0 558,232.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-2d8b926f65894b0ebb633a0ac3085069-0-6\" stroke-width=\"2px\" d=\"M150,242.0 C150,2.0 610.0,2.0 610.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-2d8b926f65894b0ebb633a0ac3085069-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M610.0,244.0 L618.0,232.0 602.0,232.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-2d8b926f65894b0ebb633a0ac3085069-0-7\" stroke-width=\"2px\" d=\"M630,242.0 C630,202.0 665.0,202.0 665.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-2d8b926f65894b0ebb633a0ac3085069-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">npadvmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M665.0,244.0 L673.0,232.0 657.0,232.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-2d8b926f65894b0ebb633a0ac3085069-0-8\" stroke-width=\"2px\" d=\"M790,242.0 C790,202.0 825.0,202.0 825.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-2d8b926f65894b0ebb633a0ac3085069-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M790,244.0 L782,232.0 798,232.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-2d8b926f65894b0ebb633a0ac3085069-0-9\" stroke-width=\"2px\" d=\"M630,242.0 C630,122.0 835.0,122.0 835.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-2d8b926f65894b0ebb633a0ac3085069-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">npadvmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M835.0,244.0 L843.0,232.0 827.0,232.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-2d8b926f65894b0ebb633a0ac3085069-0-10\" stroke-width=\"2px\" d=\"M950,242.0 C950,202.0 985.0,202.0 985.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-2d8b926f65894b0ebb633a0ac3085069-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M950,244.0 L942,232.0 958,232.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-2d8b926f65894b0ebb633a0ac3085069-0-11\" stroke-width=\"2px\" d=\"M1030,242.0 C1030,122.0 1235.0,122.0 1235.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-2d8b926f65894b0ebb633a0ac3085069-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1030,244.0 L1022,232.0 1038,232.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-2d8b926f65894b0ebb633a0ac3085069-0-12\" stroke-width=\"2px\" d=\"M1110,242.0 C1110,162.0 1230.0,162.0 1230.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-2d8b926f65894b0ebb633a0ac3085069-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1110,244.0 L1102,232.0 1118,232.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-2d8b926f65894b0ebb633a0ac3085069-0-13\" stroke-width=\"2px\" d=\"M1190,242.0 C1190,202.0 1225.0,202.0 1225.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-2d8b926f65894b0ebb633a0ac3085069-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1190,244.0 L1182,232.0 1198,232.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-2d8b926f65894b0ebb633a0ac3085069-0-14\" stroke-width=\"2px\" d=\"M870,242.0 C870,42.0 1245.0,42.0 1245.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-2d8b926f65894b0ebb633a0ac3085069-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1245.0,244.0 L1253.0,232.0 1237.0,232.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-2d8b926f65894b0ebb633a0ac3085069-0-15\" stroke-width=\"2px\" d=\"M1270,242.0 C1270,202.0 1305.0,202.0 1305.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-2d8b926f65894b0ebb633a0ac3085069-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1305.0,244.0 L1313.0,232.0 1297.0,232.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-2d8b926f65894b0ebb633a0ac3085069-0-16\" stroke-width=\"2px\" d=\"M1270,242.0 C1270,162.0 1390.0,162.0 1390.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-2d8b926f65894b0ebb633a0ac3085069-0-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1390.0,244.0 L1398.0,232.0 1382.0,232.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WIoT2mXy5cws"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Named entity recognition\n",
        "### usually for recognition of companies, industries.."
      ],
      "metadata": {
        "id": "s6zmNxFh7rMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s1 = 'Tesla is a U.S. based car manufacturing company of $1 billion.'\n",
        "s2 = 'Elon Musk is the CEO of Tesla.'\n",
        "s3 = 'Elon Musk is a crazy guy and his company SpaceX is amazingly aiming for moon.'"
      ],
      "metadata": {
        "id": "JlSz3DgE5cy6"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc1 = nlp(s1)\n",
        "doc2 = nlp(s2)\n",
        "doc3 = nlp(s3)\n",
        "\n",
        "print(doc1.ents, doc2.ents, doc3.ents)\n",
        "\n",
        "for ent in doc1.ents:\n",
        "  print(ent.text, ent.label_, str(spacy.explain(ent.label_)))\n",
        "\n",
        "for ent in doc3.ents:\n",
        "  print(ent.text, ent.label_, str(spacy.explain(ent.label_)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMCOhBiA5c1I",
        "outputId": "4b410c24-f032-48e6-e8ae-803e1e83248a"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Tesla, U.S., $1 billion) (Elon Musk, Tesla) (Elon Musk, moon)\n",
            "Tesla ORG Companies, agencies, institutions, etc.\n",
            "U.S. GPE Countries, cities, states\n",
            "$1 billion MONEY Monetary values, including unit\n",
            "Elon Musk PERSON People, including fictional\n",
            "moon PERSON People, including fictional\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### SpaceX is not recognized\n",
        "### let's add it to vocabulary\n",
        "\n",
        "from spacy.tokens import Span\n",
        "\n",
        "ORG = doc3.vocab.strings['ORG']\n",
        "new_ent = Span(doc3, 9, 10, label=ORG)\n",
        "\n",
        "doc3.ents = list(doc3.ents) + [new_ent]\n",
        "\n",
        "doc3.ents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvQ9DASp5c3T",
        "outputId": "d3bfe0b4-8375-476d-e7ee-cad4860a21ff"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Elon Musk, SpaceX, moon)"
            ]
          },
          "metadata": {},
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### checking\n",
        "for ent in doc3.ents:\n",
        "  print(ent.text, ent.label_, str(spacy.explain(ent.label_)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uZwJwYh8fua",
        "outputId": "786966d0-02bf-44a0-cdb3-b62e0d2f531d"
      },
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elon Musk PERSON People, including fictional\n",
            "SpaceX ORG Companies, agencies, institutions, etc.\n",
            "moon PERSON People, including fictional\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "displacy.render(docs=doc1, style='ent', jupyter=True)\n",
        "displacy.render(docs=doc2, style='ent', jupyter=True)\n",
        "displacy.render(docs=doc3, style='ent', options={'ents': ['ORG']}, jupyter=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "NHzFOw0Z8fwm",
        "outputId": "41c93ecc-f86b-4dd6-f5b5-a3d7dfd2564f"
      },
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Tesla\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " is a \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    U.S.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " based car manufacturing company of \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    $1 billion\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
              "</mark>\n",
              ".</div></span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Elon Musk\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " is the CEO of \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Tesla\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ".</div></span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Elon Musk is a crazy guy and his company \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    SpaceX\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " is amazingly aiming for moon.</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Rtm0iBhX8fy6"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentence Segmentation"
      ],
      "metadata": {
        "id": "lsw8Ngc4_2Gs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s1 = 'Tesla is a company. It is in U.S. . Car manufacturing company of $1 billion.'\n",
        "s2 = 'Tesla is a company; It is a U.S.; Car manufacturing company of $1 billion.'"
      ],
      "metadata": {
        "id": "mSxGZFhk8f06"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### multiple sentences\n",
        "\n",
        "doc1 = nlp(s1)\n",
        "for sent in doc1.sents:\n",
        "  print(sent.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXaOzllAAOIk",
        "outputId": "09b26d40-ddab-433e-e9e4-246c74f38084"
      },
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla is a company.\n",
            "It is in U.S. .\n",
            "Car manufacturing company of $1 billion.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### recognized as 1 sentence only\n",
        "\n",
        "doc2 = nlp(s2)\n",
        "for sent in doc2.sents:\n",
        "  print(sent.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imBQIEqHAOLJ",
        "outputId": "65322b3e-553b-4e8b-f485-c0ec4ed76fc5"
      },
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla is a company; It is a U.S.; Car manufacturing company of $1 billion.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Adding new rules for sentence segmentation"
      ],
      "metadata": {
        "id": "DKN6JDc1BGAE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_custom_boundaries(doc):\n",
        "  for token in doc[:-1]:\n",
        "    if token.text == ';':\n",
        "      print(token.i)\n",
        "      ### after detection of semi-colon, make 'is new sentence starting' true\n",
        "      doc[token.i+1].is_sent_start = True\n",
        "  return doc\n"
      ],
      "metadata": {
        "id": "ZxblH_RW8f3C"
      },
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### nlp pipeline\n",
        "### 1. tagging, 2. parsing and 3. name entity recognition\n",
        "nlp.pipe_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ujP-y2yBhQi",
        "outputId": "e3f173fc-fcd2-43ef-85d6-d5cc3452419d"
      },
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tagger', 'parser', 'ner']"
            ]
          },
          "metadata": {},
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### In which part of nlp pipeline we want to add this rule\n",
        "### before parser\n",
        "\n",
        "nlp.add_pipe(set_custom_boundaries, before='parser')\n",
        "nlp.pipe_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgPPKR87BhSw",
        "outputId": "e9110420-9e97-43fa-ed19-40ebfc7c0728"
      },
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tagger', 'set_custom_boundaries', 'parser', 'ner']"
            ]
          },
          "metadata": {},
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc_2 = nlp(s2)\n",
        "for sent in doc_2.sents:\n",
        "  print(sent.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CarHshQ4BhUx",
        "outputId": "9487e208-0c7a-4b6b-dde6-dc9cfd2d36d4"
      },
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "9\n",
            "Tesla is a company;\n",
            "It is a U.S.;\n",
            "Car manufacturing company of $1 billion.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JANiyl8tBELF"
      },
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Di3KuDMpBENu"
      },
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OO9AWDBdBEPT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}